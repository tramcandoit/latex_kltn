Chương này tập trung trình bày các kịch bản thực nghiệm nhằm đánh giá hiệu quả của hệ thống phát hiện gian lận và hệ thống MLSecOps đề xuất. Nội dung chương bao gồm việc xây dựng kịch bản thực nghiệm, lựa chọn các tiêu chí đánh giá phù hợp với dữ liệu mất cân bằng, phân tích kết quả hoạt động của các mô hình phát hiện gian lận, cũng như đánh giá tác động của tấn công lật nhãn đến hiệu năng mô hình. Bên cạnh đó, chương này còn trình bày các thực nghiệm liên quan đến triển khai hệ thống MLSecOps trên môi trường Kubernetes, qua đó phân tích hiệu năng của hệ thống, mức sử dụng tài nguyên và hiệu quả của cơ chế song song hóa dựa trên kiến trúc \ac{dag}.

\section{Thực nghiệm hệ thống học máy phát hiện gian lận}

\subsection{Tiêu chí đánh giá}

Trong bài toán phát hiện gian lận, các chỉ số như Accuracy có thể bị sai lệch do sự mất cân bằng dữ liệu. Ví dụ, khi phần lớn giao dịch là không gian lận, một mô hình dự đoán tất cả các giao dịch đều không gian lận vẫn có thể đạt độ chính xác cao nhưng không có giá trị thực tiễn. Do đó, Confusion Matrix và AUC-ROC được sử dụng nhằm đánh giá chi tiết các trường hợp dự đoán đúng và sai, cũng như khả năng phân biệt giữa hai lớp của mô hình một cách khách quan hơn.

\subsubsection{Confusion Matrix}

Confusion Matrix được sử dụng để đánh giá chi tiết kết quả phân loại của mô hình phát hiện gian lận. Các metric được tóm tắt trong Bảng~\ref{tab:confusion-matrix-metrics}.

\begin{table}[!htbp]
\centering
\caption{Các tiêu chí đánh giá dựa trên Confusion Matrix}
\label{tab:confusion-matrix-metrics}
\renewcommand{\arraystretch}{1.2}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} l l p{7cm}}
\toprule
\textbf{Metric} & \textbf{Công thức} & \textbf{Mô tả} \\
\midrule

True Positive (TP) &
-- &
Giao dịch gian lận được mô hình dự đoán đúng là gian lận. \\

False Negative (FN) &
-- &
Giao dịch gian lận nhưng bị mô hình dự đoán nhầm là không gian lận; đây là trường hợp rủi ro cao trong bài toán phát hiện gian lận. \\

False Positive (FP) &
-- &
Giao dịch hợp lệ nhưng bị mô hình dự đoán nhầm là gian lận, gây ra báo động giả. \\

True Negative (TN) &
-- &
Giao dịch hợp lệ được mô hình dự đoán đúng là không gian lận. \\

\addlinespace
Recall (TPR) &
$\displaystyle \frac{TP}{TP + FN}$ &
Tỷ lệ giao dịch gian lận thực tế được mô hình phát hiện; metric được ưu tiên trong bài toán phát hiện gian lận. \\

Precision &
$\displaystyle \frac{TP}{TP + FP}$ &
Tỷ lệ các giao dịch được dự đoán là gian lận thực sự là gian lận; phản ánh mức độ tin cậy của cảnh báo. \\

False Positive Rate (FPR) &
$\displaystyle \frac{FP}{FP + TN}$ &
Tỷ lệ giao dịch hợp lệ bị dự đoán nhầm là gian lận; được sử dụng để xây dựng đường cong ROC. \\

\bottomrule
\end{tabular*}
\end{table}

Trong bài toán phát hiện gian lận, việc giảm thiểu False Negative có ý nghĩa quan trọng hơn so với giảm False Positive. Nguyên nhân là do các trường hợp gian lận không được phát hiện kịp thời có thể gây ra tổn thất trực tiếp, làm suy giảm độ tin cậy của hệ thống và ảnh hưởng đến uy tín của tổ chức. Ngược lại, các trường hợp False Positive tuy có thể gây ra sự bất tiện hoặc phát sinh chi phí kiểm tra bổ sung, nhưng mức độ rủi ro thường thấp hơn so với việc bỏ sót các giao dịch gian lận. Ngoài ra, True Positive Rate và False Positive Rate là hai thành phần chính được sử dụng để xây dựng đường cong ROC, giúp đánh giá tổng quan hiệu suất phân loại của mô hình.

\subsubsection{AUC-ROC}

AUC-ROC được sử dụng để đánh giá khả năng phân biệt giữa hai lớp của mô hình phân loại thông qua mối quan hệ giữa tỷ lệ dương tính thật (TPR) và tỷ lệ dương tính giả (FPR). Các khái niệm và tiêu chí liên quan được tóm tắt trong Bảng~\ref{tab:roc-auc-metrics}.

\begin{table}[!htbp]
\centering
\caption{Các khái niệm và tiêu chí đánh giá dựa trên AUC-ROC}
\label{tab:roc-auc-metrics}
\renewcommand{\arraystretch}{1.2}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} l l p{7cm}}
\toprule
\textbf{Metric} & \textbf{Công thức} & \textbf{Mô tả} \\
\midrule

True Positive Rate (TPR) &
$\displaystyle \frac{TP}{TP + FN}$ &
Tỷ lệ mẫu dương tính (gian lận) được dự đoán đúng trên tổng số mẫu thực tế dương tính. Còn gọi là Recall/Sensitivity. \\

False Positive Rate (FPR) &
$\displaystyle \frac{FP}{FP + TN}$ &
Tỷ lệ mẫu âm tính (hợp lệ) bị dự đoán sai thành dương tính trên tổng số mẫu thực tế âm tính. \\

ROC Curve &
Đồ thị (FPR, TPR) &
Đường cong biểu diễn sự đánh đổi giữa TPR và FPR tại các ngưỡng phân loại (threshold) khác nhau. \\

AUC-ROC &
$\displaystyle \int_{0}^{1} \text{ROC}(x)\,dx$ &
Diện tích dưới đường cong ROC. Phản ánh khả năng phân biệt tổng quát giữa hai lớp:
\begin{itemize}[leftmargin=*, nosep]
    \item AUC $\approx 1$: Mô hình phân loại hoàn hảo.
    \item AUC $\approx 0.5$: Mô hình dự đoán ngẫu nhiên.
\end{itemize} \\

\bottomrule
\end{tabular*}
\end{table}


\subsection{Kết quả mô hình phát hiện gian lận}

Mô hình thực nghiệm được triển khai dựa trên các phương pháp đã nêu ở phần trước. Trong đó, dữ liệu thực nghiệm và quy trình xử lý dữ liệu được mô tả trong phần \ref{subsec:introduce-dataset}, cấu hình mô hình được mô tả trong phần \ref{subsec:train-model}.

Bảng \ref{tab:model_performance} tóm tắt hiệu suất của hai mô hình XGBoost và \ac{brf} trên tập kiểm thử (Test). Hình \ref{fig:chap4-model-auc.png} minh họa đường cong ROC và Hình \ref{fig:chap4-xgb-brf-cm.png} chi tiết hóa các kết quả dự đoán thông qua Confusion Matrix.

\begin{table}[!htbp]
    \centering
    \caption{Kết quả đánh giá mô hình trên tập Test}
    \label{tab:model_performance}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} lccc}
        \toprule
        \textbf{Mô hình} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC-ROC} \\
        \midrule
        XGBoost & 6,02\% & 66,12\% & 0,8725 \\
        \addlinespace
        Balanced Random Forest & 4,17\% & 79,94\% & 0,8755 \\
        \bottomrule
    \end{tabular*}
\end{table}

Quan sát kết quả thực nghiệm, cả hai mô hình đều thể hiện khả năng phân tách tốt giữa hai lớp dữ liệu với chỉ số AUC đều đạt mức xấp xỉ 0.87. Tuy nhiên, khi đi sâu vào chi tiết hiệu năng phân loại, chúng ta có thể thấy một số khác biệt trong chiến lược của từng mô hình.

Mô hình \ac{brf} cho thấy sự vượt trội trong khả năng bắt các trường hợp dương tính (Positive) với chỉ số Recall đạt 79.94\%, cao hơn đáng kể so với mức 66.12\% của XGBoost. Điều này đồng nghĩa với việc mô hình đã nhận diện chính xác gần 80\% số trường hợp thực tế cần quan tâm. Tuy nhiên, việc tối ưu hóa Recall đã dẫn đến sự đánh đổi mạnh mẽ về độ chính xác (Precision), khi chỉ số này giảm xuống mức 4.17\%. 

Với các thách thức đã biết trong bài toán phát hiện gian lận, mức Precision thấp này cảnh báo rằng phần lớn các trường hợp được mô hình dán nhãn là "Dương tính" thực chất là báo động giả (False Positive). Mặc dù tỷ lệ báo động giả cao có thể gây lãng phí tài nguyên kiểm tra lại, nhưng trong bối cảnh bài toán ưu tiên giảm thiểu rủi ro bỏ sót (False Negative) để tránh các hậu quả nghiêm trọng, kết quả của 2 mô hình có thể xem là phù hợp và an toàn.

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.3]{img/chapter4/chap4-model-auc.png}
    \caption{Đường cong ROC của XGBoost và Balanced RF}
    \label{fig:chap4-model-auc.png}
\end{figure}

\begin{figure}[!htbp]
    \centering
    
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/chapter4/chap4-xgb_confusion_matrix.png}
        \caption{XGBoost}
        \label{fig:chap4-xgb_confusion_matrix.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/chapter4/chap4-brf_confusion_matrix.png}
        \caption{Balanced RF}
        \label{fig:chap4-brf_confusion_matrix.png}
    \end{subfigure}
    
    \caption{Confusion Matrix của các mô hình}
    \label{fig:chap4-xgb-brf-cm.png}
\end{figure}

\subsection{Đánh giá tác động của tấn công lật nhãn đến hiệu quả mô hình}
\label{subsec:label-attack-to-model}

Để đánh giá mức độ ảnh hưởng của tấn công lật nhãn đến hiệu quả của các mô hình phát hiện gian lận, nhóm sinh viên xây dựng một kịch bản mô phỏng trong đó nhãn của một phần dữ liệu huấn luyện bị thay đổi có chủ đích. Cụ thể, tập dữ liệu huấn luyện bị lật lần lượt 5\,000, 10\,000 và 20\,000 nhãn nhằm mô phỏng các mức độ tấn công khác nhau, từ nhẹ đến nghiêm trọng.

Trong quá trình tạo dữ liệu bị tấn công, việc lật nhãn hoàn toàn ngẫu nhiên có thể dẫn đến tình trạng phần lớn hoặc toàn bộ các nhãn gian lận ban đầu bị đảo ngược, khiến mô hình không còn đủ mẫu gian lận thực để học và dẫn đến hành vi dự đoán gần như ngẫu nhiên. Do đó, số lượng nhãn gian lận bị lật được kiểm soát nhằm đảm bảo vẫn tồn tại một tỷ lệ nhãn gian lận thực trong dữ liệu huấn luyện, đồng thời phản ánh đúng bản chất của tấn công lật nhãn trong các hệ thống thực tế.

Để định lượng tác động của tấn công lật nhãn, nhóm sinh viên xem xét hai khía cạnh:  
(i) sự suy giảm của số lượng gian lận thật còn lại trong dữ liệu huấn luyện, và  
(ii) sự biến động của số lượng nhãn gian lận quan sát được sau khi bị tấn công.

Gọi $N_{org}$ là số lượng gian lận ban đầu trong tập huấn luyện, $N_{F \to N}$ là số lượng nhãn gian lận bị lật thành bình thường, và $N_{N \to F}$ là số lượng nhãn bình thường bị lật thành gian lận. Khi đó, số lượng gian lận quan sát được sau tấn công $N_{new}$ được xác định như sau:

\begin{equation}
N_{\text{new}} = N_{\text{org}} - N_{F \to N} + N_{N \to F}
\label{eq:population-update}
\end{equation}

Dựa trên đó, tỷ lệ biến động của số lượng gian lận quan sát được sau tấn công được tính bằng:

\begin{equation}
\Delta_{\text{new}} (\%) = \left( \frac{N_{\text{new}} - N_{\text{org}}}{N_{\text{org}}} \right) \times 100
\label{eq:percentage-change}
\end{equation}

Mặt khác, để phản ánh trực tiếp mức độ suy giảm của tín hiệu học tập từ các mẫu gian lận thật, tỷ lệ suy giảm gian lận thật còn lại trong dữ liệu huấn luyện được định nghĩa như sau:

\begin{equation}
\Delta_{\text{true}} (\%) = \left( - \frac{N_{F \to N}}{N_{\text{org}}} \right) \times 100
\label{eq:delta-true}
\end{equation}

Trong đó, $\Delta_{\text{true}}$ biểu thị mức độ mất mát các mẫu gian lận thực mà mô hình có thể học được, trong khi $\Delta_{\text{new}}$ phản ánh sự biến động về mặt thống kê của nhãn gian lận quan sát được sau tấn công. Hai đại lượng này cho phép phân tích rõ ràng sự khác biệt giữa nhiễu nhãn do tấn công gây ra và sự suy giảm thực chất của thông tin huấn luyện.

Chi tiết phân bổ số lượng nhãn bị lật và mức độ biến động của tập dữ liệu trong từng kịch bản tấn công được trình bày trong Bảng~\ref{tab:dataset_split_flip}.

\begin{table}[!htbp]
    \centering
    \caption{Phân bổ số lượng nhãn bị lật và mức độ biến động của gian lận}
    \label{tab:dataset_split_flip}
    \renewcommand{\arraystretch}{0.9}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} ccccccc}
        \toprule
        \textbf{Số nhãn bị lật} &
        \textbf{$N_{org}$} &
        \textbf{$N_{F \to N}$} &
        \textbf{$N_{N \to F}$} &
        \textbf{$\Delta_{\text{true}}$} &
        \textbf{$\Delta_{\text{new}}$} \\
        \midrule
        0      & 9.601 & 0     & 0      & 0.00   & 0.00   \\
        \addlinespace
        5.000  & 9.601 & 2.400 & 2.600  & -25.00\% & +2.08\%  \\
        \addlinespace
        10.000 & 9.601 & 4.801 & 5.199  & -50.01\% & +4.15\%  \\
        \addlinespace
        20.000 & 9.601 & 7.201 & 12.799 & -75.00\% & +58.31\% \\
        \bottomrule
    \end{tabular*}
\end{table}


Bảng \ref{tab:model_performance_flipped} trình bày hiệu năng của hai mô hình XGBoost và \ac{brf} tương ứng với từng mức độ lật nhãn, được đánh giá trên cả tập kiểm tra (Test) và tập dữ liệu mô phỏng kịch bản thực tế (Out-of-time Test Set -- OOT). Hình~\ref{fig:chap4-roc-curves-oot} minh họa đường cong ROC của hai mô hình trên tập OOT tương ứng với các mức độ lật nhãn khác nhau.

\begin{table}[!htbp]
    \centering
    \caption{Hiệu năng mô hình theo số lượng mẫu bị lật nhãn}
    \label{tab:model_performance_flipped}
    \renewcommand{\arraystretch}{0.9}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} llcccc}
        \toprule
        \multirow{2}{*}{\textbf{Mô hình}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{4}{c}{\textbf{Số nhãn bị lật}} \\
        \cmidrule(lr){3-6}
         & & \textbf{0} & \textbf{5.000} & \textbf{10.000} & \textbf{20.000} \\
        \midrule
        
        % --- XGBOOST SECTION ---
        \multirow{7}{*}{\textbf{XGBoost}} 
         & \multicolumn{5}{l}{\textit{On Test Set}} \\
         & \hspace{3mm} Precision & 6.02\% & 4.05\% & 2.68\% & 1.96\% \\
         & \hspace{3mm} Recall & 66.12\% & 50.43\% & 38.14\% & 27.60\% \\
         & \hspace{3mm} AUC-ROC & 0.87 & 0.75 & 0.64 & 0.53 \\
         \cmidrule(lr){2-6}
         & \multicolumn{5}{l}{\textit{On OOT Test Set}} \\
         & \hspace{3mm} Precision & 7.14\% & 6.26\% & 4.51\% & 2.52\% \\
         & \hspace{3mm} Recall & 62.26\% & 58.68\% & 52.35\% & 34.79\% \\
         & \hspace{3mm} AUC-ROC & 0.84 & 0.79 & 0.73 & 0.59 \\
        
        \midrule
        
        % --- BALANCED RF SECTION ---
        \multirow{7}{*}{\textbf{\ac{}}} 
         & \multicolumn{5}{l}{\textit{On Test Set}} \\
         & \hspace{3mm} Precision & 4.17\% & 3.18\% & 2.11\% & 1.91\% \\
         & \hspace{3mm} Recall & 79.94\% & 64.94\% & 51.58\% & 48.01\% \\
         & \hspace{3mm} AUC-ROC & 0.88 & 0.77 & 0.65 & 0.54 \\
         \cmidrule(lr){2-6}
         & \multicolumn{5}{l}{\textit{On OOT Test Set}} \\
         & \hspace{3mm} Precision & 8.09\% & 7.30\% & 5.44\% & 2.92\% \\
         & \hspace{3mm} Recall & 71.54\% & 71.75\% & 73.86\% & 73.01\% \\
         & \hspace{3mm} AUC-ROC & 0.88 & 0.86 & 0.84 & 0.75 \\
         
        \bottomrule
    \end{tabular*}
\end{table}

\begin{figure}[ht]
    \centering
    
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/chapter4/chap4-xgb-roc-compare-oot.png}
        \caption{XGBoost}
        \label{fig:chap4-xgb-roc-compare-oot.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/chapter4/chap4-brf-roc-compare-oot.png}
        \caption{Balanced RF}
        \label{fig:chap4-brf-roc-compare-oot.png}
    \end{subfigure}
    
    \caption{Đường cong ROC của các mô hình bị tấn công lật nhãn}
    \label{fig:chap4-roc-curves-oot}
\end{figure}


Trên tập dữ liệu kiểm tra (Test), kết quả cho thấy khi số lượng nhãn bị lật tăng lên, hiệu năng của các mô hình suy giảm rõ rệt, thể hiện qua sự sụt giảm của chỉ số AUC-ROC. Khi mức độ nhiễu nhãn gia tăng, tương ứng với việc giá trị $\Delta_{\text{true}}$ ngày càng giảm mạnh, mô hình không còn đủ thông tin để học các đặc trưng phân biệt giữa giao dịch gian lận và không gian lận. Điều này cho thấy ngay cả trên tập Test, vốn được chia trực tiếp từ dữ liệu đã bị lật nhãn và có cùng phân bố với tập Train, khả năng phân lớp của mô hình vẫn bị ảnh hưởng nghiêm trọng.

Trên tập dữ liệu mô phỏng dữ liệu thực tế (OOT Test), đại diện cho kịch bản triển khai thực tế, sự suy giảm hiệu năng của các mô hình còn rõ rệt hơn. Mặc dù tập OOT không trực tiếp chịu tác động của quá trình lật nhãn, hiệu năng thấp trên tập này phản ánh hệ quả gián tiếp của việc mô hình đã học được các ranh giới phân lớp sai lệch từ dữ liệu huấn luyện bị nhiễu nhãn. Điều này thể hiện qua việc các đường cong ROC trên tập OOT có xu hướng tiến gần hơn đến đường chéo của bộ phân loại ngẫu nhiên (Hình \ref{fig:chap4-roc-curves-oot}).

Những kết quả này cho thấy các mô hình phát hiện gian lận dễ bị tổn thương trước tấn công lật nhãn, từ đó cho thấy sự cần thiết phải có các phương pháp phát hiện và giảm thiểu tác động của tấn công lật nhãn trong dữ liệu huấn luyện.


\subsection{Đánh giá kết quả phương pháp phát hiện tấn công lật nhãn}

Để đánh giá kết quả của phương pháp phát hiện tấn công lật nhãn đề xuất, nhóm sinh viên đã triển khai các kịch bản phát hiện lật nhãn, phương pháp được triển khai với tập trọng số được lựa chọn cố định, trong đó chỉ số PLE, Disagreement và Boundary lần lượt có trọng số $w_1 = 0.65$, $w_2 = 0.25$ và $w_3 = 0.10$. Việc ưu tiên trọng số lớn hơn cho PLE nhằm nhấn mạnh mức độ mâu thuẫn giữa nhãn quan sát và dự đoán của mô hình, trong khi hai chỉ số còn lại đóng vai trò bổ trợ để phản ánh tính không ổn định và độ khó phân loại của dữ liệu.

Bên cạnh đó, tham số tỷ lệ lựa chọn $r$ được thiết lập ở mức $6\%$, tức là sau khi xếp hạng các điểm dữ liệu theo mức độ nghi ngờ lật nhãn, thuật toán chỉ giữ lại $6\%$ số điểm dữ liệu có điểm nghi ngờ cao nhất để đưa vào tập cần kiểm tra thủ công.

Trong thí nghiệm kiểm tra này, nhãn của một phần dữ liệu được lật ngẫu nhiên với quy mô lần lượt là 5\,000, 10\,000 và 20\,000 điểm dữ liệu (tương tự \ref{subsec:label-attack-to-model}). Thuật toán phát hiện lật nhãn được áp dụng trên các tập dữ liệu này nhằm đánh giá mức độ bao phủ các nhãn bị lật, được đo lường thông qua chỉ số Recall.

Bảng \ref{tab:label_flip_detection_result} cho thấy phương pháp có khả năng phát hiện tốt các nhãn bị lật trong cả ba kịch
bản thử nghiệm. Cụ thể, khi số lượng nhãn bị lật là 5\,000, phương pháp phát hiện đúng
4\,013 nhãn bị lật, tương ứng Recall đạt 80.01\%. Với 10\,000 nhãn bị lật, Recall vẫn duy trì ở mức 80.00\%, cho thấy khả năng bắt đúng nhãn bị lật ổn định khi mức độ tấn công gia tăng. Trong kịch bản nghiêm trọng hơn với 20\,000 nhãn bị lật, Recall giảm nhẹ xuống 77.80\%, phản ánh độ khó tăng lên của bài toán khi tỷ lệ nhiễu nhãn trong dữ liệu lớn trong khi tỉ lệ kiểm tra nhỏ.

\begin{table}[!htbp]
    \centering
    \caption{Kết quả phát hiện lật nhãn với các mức độ tấn công khác nhau}
    \label{tab:label_flip_detection_result}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} lcccccc}
        \toprule
        \textbf{Số nhãn bị lật} & \textbf{$\Delta_{\text{true}}$} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{TN} & \textbf{Recall} \\
        \midrule
        5.000  & -25,00\% & 4.013 & 49.856 & 964   & 842.969 & 80,01\% \\
        \addlinespace
        10.000 & -50,01\% & 8.009 & 45.860 & 1.944 & 841.989 & 80,00\% \\
        \addlinespace
        20.000 & -75,00\% & 15.480 & 38.389 & 4.417 & 839.516 & 77,80\% \\
        \bottomrule
    \end{tabular*}
\end{table}


Các kết quả trên được thu được trong điều kiện tham số tỷ lệ lựa chọn $r$ được cố định ở mức $6\%$, tức là thuật toán chỉ đề xuất một tập con tương đối nhỏ các điểm dữ liệu để đưa vào kiểm tra thủ công.

Trong thực tế, nếu mục tiêu là tăng khả năng phát hiện nhãn bị lật và giảm thiểu số lượng nhãn sai bị bỏ sót, tham số $r$ có thể được mở rộng để tăng phạm vi kiểm tra. Tuy nhiên, việc này đồng nghĩa với việc gia tăng chi phí kiểm tra thủ công, tạo ra sự đánh đổi giữa hiệu quả phát hiện và khả năng vận hành của đội ngũ dữ liệu trong quy trình human-in-the-loop.

\section{Thực nghiệm hệ thống MLSecOps}
\subsection{Môi trường thực nghiệm}

Các kết quả thực nghiệm trong phần này được thực hiện trên cụm Kubernetes được triển khai trên \ac{EKS} với cấu hình:
\begin{itemize}
    \item \textbf{Nodes}: 4 × t3.large
    \item \textbf{Cấu hình mỗi Node}: 2 vCPUs, 8 GB RAM
    \item \textbf{Tổng tài nguyên của cụm}: 8 vCPUs, 32 GB RAM
\end{itemize}

Cấu hình của quy trình tái huấn luyện (retrain pipeline) được thực thi với các tham số sau:
\begin{itemize}
    \item \textbf{Replay Ratio}: 1.0 (sử dụng lại toàn bộ dữ liệu cũ)
    \item \textbf{Max Items}: 10000 (thêm 10.000 điểm dữ liệu mới từ production)
\end{itemize}

Tập dữ liệu huấn luyện mô hình bao gồm toàn bộ tập \textbf{Train/Test}, dữ liệu mới dùng cho tái huấn luyện mô hình được trích từ tập \textbf{Out-of-time Test Set}. Chi tiết được mô tả tại Bảng \ref{tab:dataset_split}.

\subsection{Đánh giá hiệu năng hệ thống MLSecOps}
\label{subsec:mlsecops-sys-eval}
Trong phần này, nhóm tiến hành đánh giá hiệu năng hệ thống MLSecOps trong quá trình thực thi pipeline huấn luyện và tái huấn luyện mô hình. Việc đánh giá tập trung vào mức tiêu thụ tài nguyên hệ thống của từng bước trong pipeline nhằm làm rõ đặc tính tính toán, xác định các bước có nguy cơ trở thành nút thắt hiệu năng, đồng thời cung cấp cơ sở cho việc tối ưu và mở rộng hệ thống trong tương lai.

Hai chỉ số hiệu năng chính được theo dõi là mức sử dụng CPU và bộ nhớ của các pod trong hệ thống. Các chỉ số này được Prometheus thu thập trong suốt quá trình thực thi pipeline và được trực quan hóa thông qua các dashboard Grafana, cho phép quan sát trực tiếp sự biến động tài nguyên theo thời gian.

Cụ thể, mức sử dụng CPU được đo bằng chỉ số container\_cpu\_usage\_rate, phản ánh số nhân CPU mà mỗi pod sử dụng trung bình tại một thời điểm. Trong khi đó, mức sử dụng bộ nhớ được đo bằng container\_memory\_working\_set, đại diện cho lượng bộ nhớ thực tế mà pod đang chiếm giữ trong quá trình xử lý. Việc lựa chọn hai chỉ số này giúp phản ánh chính xác cường độ tính toán và nhu cầu lưu trữ dữ liệu của từng bước trong pipeline MLSecOps.

Bảng \ref{tab:detailed_resource_metrics} cung cấp cái nhìn tổng hợp về thời gian thực thi và mức tiêu thụ tài nguyên của từng bước trong pipeline MLSecOps cho cả hai kịch bản huấn luyện và tái huấn luyện mô hình.

\label{sec:4.2.1}
%TODO
\begin{table}[!htbp]
    \centering
    \caption{Chi tiết tài nguyên hệ thống và thời gian thực thi theo từng bước của Pipeline}
    \label{tab:detailed_resource_metrics}
    \footnotesize
    \setlength{\tabcolsep}{1.5pt}
    
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} ll ccccc cc c}
        \toprule
        \multirow{2.5}{*}{\textbf{Pipe.}} & \multirow{2.5}{*}{\textbf{Metrics}} 
        & \multicolumn{2}{c}{\textbf{prepare}} 
        & \multirow{2}{*}{\makecell{\textbf{merge}\\\textbf{data}}} 
        & \multirow{2}{*}{\makecell{\textbf{sec.}\\\textbf{check}}} 
        & \multirow{2}{*}{\makecell{\textbf{pre-}\\\textbf{process}}} 
        & \multicolumn{2}{c}{\textbf{train}} 
        & \multirow{2}{*}{\makecell{\textbf{com-}\\\textbf{pare}}} \\
        \cmidrule(lr){3-4} \cmidrule(lr){8-9}
        & & fetch & base & & & & brf & xgb & \\
        \midrule
        
        % --- TRAINING ---
        \multirow{5}{*}{\rotatebox[origin=c]{90}{\textbf{Training}}} 
        & Duration (s)      & --- & 8    & --- & 139 & 113 & 86  & 69  & 27 \\
        & Avg. CPU (c)      & --- & N/A  & --- & 0.1313 & 0.1304 & 0.0715 & 0.0498 & N/A \\
        & Peak CPU (c)     & --- & N/A  & --- & 0.1690 & 0.1750 & 0.1460 & 0.0967 & N/A \\
        & Avg. Mem (MB)    & --- & 7.96 & --- & 1381.93 & 587.96 & 701.79 & 587.37 & 20.50 \\
        & Peak Mem (MB)   & --- & 7.96 & --- & 1638.40 & 991.00 & 821.00 & 702.00 & 21.50 \\
        
        \midrule
        
        % --- RETRAINING ---
        \multirow{5}{*}{\rotatebox[origin=c]{90}{\textbf{Retraining}}} 
        & Duration (s)     & 9    & 9    & 62  & 131 & 124 & 90  & 73  & 26 \\
        & Avg. CPU (c)     & N/A  & N/A  & 0.0889 & 0.1213 & 0.1506 & 0.1169 & 0.0872 & 0.0005 \\
        & Peak CPU (c)    & N/A  & N/A  & 0.0957 & 0.1600 & 0.2010 & 0.1430 & 0.1020 & 0.0005 \\
        & Avg. Mem (MB)   & 6.74 & 7.87 & 730.17 & 1423.78 & 316.13 & 408.59 & 420.29 & 3.55 \\
        & Peak Mem (MB)  & 6.74 & 7.87 & 763.00 & 1648.64 & 1095.68 & 811.00 & 903.00 & 3.55 \\
        
        \bottomrule
    \end{tabular*}
\end{table}


\subsubsection{Mức nhân CPU pod sử dụng}

\begin{figure}[!htbp]
    \centering
    
    \begin{subfigure}[b]{1.0\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{img/chapter4/grafana-cpu-time-series.png}
        \caption{Huấn luyện mô hình}
        \label{fig:chap4-grafana-cpu-1}
    \end{subfigure}
    
    \vspace{1cm}

    \begin{subfigure}[b]{1.0\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{img/chapter4/cpu-retrain.png}
        \caption{Tái huấn luyện mô hình}
        \label{fig:chap4-grafana-cpu-2}
    \end{subfigure}
    
    \caption{Biểu đồ mức nhân CPU pod sử dụng trung bình trong từng quy trình}
    \label{fig:chap4-grafana-cpu}
\end{figure}

\paragraph{Huấn luyện mô hình}

Hình \ref{fig:chap4-grafana-cpu-1} minh họa mức sử dụng CPU của các pod trong quá trình huấn luyện mô hình. Biểu đồ cho thấy mức tiêu thụ CPU thay đổi rõ rệt giữa các bước trong pipeline, phản ánh sự khác biệt về cường độ tính toán của từng tác vụ.

Quan sát từ biểu đồ cho thấy các bước liên quan đến kiểm tra tấn công lật nhãn (security check) và huấn luyện mô hình có mức sử dụng CPU cao hơn đáng kể so với các bước còn lại. Đặc biệt, bước security check thể hiện mức sử dụng CPU cao và duy trì ổn định trong suốt thời gian thực thi, cho thấy đây là bước có cường độ xử lý lớn và có khả năng trở thành nút thắt hiệu năng của pipeline nếu không được cấp phát tài nguyên phù hợp.

Ngược lại, các bước như chuẩn bị dữ liệu hoặc so sánh mô hình có mức sử dụng CPU thấp và thời gian thực thi ngắn, cho thấy các bước này không tạo áp lực đáng kể lên tài nguyên tính toán của hệ thống.

\paragraph{Tái huấn luyện mô hình}
Hình \ref{fig:chap4-grafana-cpu-2} minh họa mức sử dụng CPU của các pod trong hệ thống MLSecOps trong kịch bản tái huấn luyện mô hình. Nhìn chung, xu hướng sử dụng CPU cũng tương tự như quá trình huấn luyện ban đầu, tuy nhiên có sự thay đổi nhẹ về mức độ tiêu thụ tài nguyên giữa các bước. Một số bước thể hiện mức sử dụng CPU thấp hơn do dữ liệu đầu vào phần lớn đã có sẵn, trong khi các bước huấn luyện mô hình và tiền xử lý vẫn duy trì mức sử dụng CPU đáng kể.

Kết quả này cho thấy pipeline MLSecOps có khả năng tận dụng lại các thành phần đã được xử lý trước đó, giúp giảm chi phí tính toán trong các lần tái huấn luyện, đồng thời vẫn đảm bảo tính toàn vẹn và an toàn của quy trình.

\subsubsection{Bộ nhớ pod sử dụng}

\begin{figure}[!htbp]
    \centering
    
    \begin{subfigure}[b]{1.0\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{img/chapter4/mem-train.png}
        \caption{Huấn luyện mô hình}
        \label{fig:chap4-grafana-mem-1}
    \end{subfigure}
    
    \vspace{1cm}

    \begin{subfigure}[b]{1.0\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{img/chapter4/mem-retrain.png}
        \caption{Tái huấn luyện mô hình}
        \label{fig:chap4-grafana-mem-2}
    \end{subfigure}
    
    \caption{Biểu đồ bộ nhớ pod tiêu thụ trong từng quy trình}
    \label{fig:chap4-grafana-mem}
\end{figure}

\paragraph{Huấn luyện mô hình}
Hình \ref{fig:chap4-grafana-mem-1} minh họa mức sử dụng bộ nhớ của các pod trong kịch bản huấn luyện mô hình. Biểu đồ cho thấy mức tiêu thụ bộ nhớ có sự khác biệt rõ rệt giữa các bước trong pipeline, phản ánh đặc điểm về xử lý và lượng dữ liệu được nạp vào bộ nhớ của từng tác vụ.

Ta có thể thấy, bước security check và huấn luyện mô hình yêu cầu lượng bộ nhớ đáng kể và duy trì mức sử dụng cao trong suốt thời gian thực thi.

\paragraph{Tái huấn luyện mô hình}
Hình \ref{fig:chap4-grafana-mem-2} cho thấy mức sử dụng bộ nhớ của các pod trong kịch bản tái huấn luyện mô hình. Nhìn chung, xu hướng tiêu thụ bộ nhớ trong giai đoạn này tương tự quá trình huấn luyện ban đầu, tuy nhiên mức sử dụng bộ nhớ ở một số bước có sự thay đổi nhẹ.

Cụ thể, các bước chuẩn bị dữ liệu thể hiện mức sử dụng bộ nhớ thấp và ổn định, do phần lớn dữ liệu đầu vào đã được xử lý và lưu trữ từ các lần huấn luyện trước. Ngược lại, bước security check tiếp tục là bước tiêu thụ bộ nhớ lớn nhất trong pipeline, với mức sử dụng bộ nhớ cao và duy trì ổn định trong suốt thời gian thực thi.

\subsection{Đánh giá hiệu quả của \ac{dag} trong hệ thống MLSecOps}

Để đánh giá tác động của kiến trúc \ac{dag} với khả năng thực thi song song lên hiệu suất của pipeline MLSecOps, nhóm sinh viên tiến hành thực nghiệm so sánh hai cấu hình:

\begin{itemize}
    \item \textbf{parallelism = 1}: Thực thi tuần tự
    \item \textbf{parallelism = 2}: Thực thi song song (cấu hình hiện tại)
\end{itemize}

\subsubsection{Phương pháp đánh giá}

Thực nghiệm sử dụng 2 metrics để đánh giá quy trình học máy được đề cập trong nghiên cứu \cite{Ramesh_2025}:

1. Pipeline Execution Time (tổng thời gian thực thi pipeline), được tính bằng công thức:

\begin{equation}
\label{eq:pipeline_time}
\text{Pipeline Execution Time} = \sum_{i=1}^{n} T_i
\end{equation}

Trong đó $T_i$ là thời gian thực thi của từng stage trong pipeline.

2. Resource Utilization (Mức độ sử dụng tài nguyên hệ thống), được tính bằng công thức:

\begin{equation}
\label{eq:resource_utilization}
\text{Resource Utilization} =
\frac{\text{Used Resources}}{\text{Total Available Resources}}
\times 100
\end{equation}

Áp dụng cho CPU và Memory để đánh giá hiệu quả sử dụng tài nguyên xử lý.

\subsubsection{Kết quả đánh giá}

Bảng~\ref{tab:compare_training_pipeline} và Bảng~\ref{tab:compare_retraining_pipeline} trình bày kết quả so sánh thời gian thực thi giữa hai cấu hình pipeline: thực thi tuần tự (parallelism = 1) và thực thi song song (parallelism = 2) đối với quy trình huấn luyện mô hình và tái huấn luyện mô hình. Hình \ref{fig:chap4-workflow-retrain-time} minh hoạ sự khác biệt về trình tự thực thi giữa 2 cấu hình.

\begin{figure}[!htbp]
    \centering
    
    \begin{subfigure}[b]{1.0\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{img/chapter4/workflow-retrain-time-1.png}
        \caption{Thực thi tuần tự (parallelism = 1)}
        \label{fig:chap4-workflow-retrain-time-1}
    \end{subfigure}
    
    \vspace{1cm}

    \begin{subfigure}[b]{1.0\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{img/chapter4/workflow-retrain-time-2.png}
        \caption{Thực thi song song (parallelism = 2)}
        \label{fig:chap4-workflow-retrain-time-2}
    \end{subfigure}
    
    \caption{Trình tự thực thi giữa 2 cấu hình trên quy trình tái huấn luyện mô hình}
    \label{fig:chap4-workflow-retrain-time}
\end{figure}

\paragraph{a. Đánh giá thời gian thực thi huấn luyện mô hình.}

Bảng~\ref{tab:compare_training_pipeline} cho thấy việc áp dụng kiến trúc DAG với khả năng song song hóa giúp giảm tổng thời gian thực thi quy trình huấn luyện mô hình. Cụ thể, \textbf{Pipeline Execution Time} \eqref{eq:pipeline_time} giảm từ 438 giây xuống còn 408 giây, tương đương mức cải thiện khoảng \textbf{6.8\%}.

\begin{table}[!htbp]
\centering
\caption{So sánh thời gian thực thi huấn luyện mô hình}
\label{tab:compare_training_pipeline}
\renewcommand{\arraystretch}{0.9}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} lcc}
    \toprule
    \textbf{Stage} & \textbf{Sequential (s)} & \textbf{Parallel (s)} \\
    \midrule
    get base data & 14 & 8 \\
    security check & 124 & 139 \\
    preprocess data & 113 & 113 \\
    \addlinespace
    \textbf{train models} & 101 & \textbf{86} \\
    \hspace{3mm} train brf & 59 & 86 \\
    \hspace{3mm} train xgb & 42 & 69 \\
    \addlinespace
    compare models & 29 & 27 \\
    Overhead time & 57 & \textbf{35} \\
    \midrule
    \textbf{Pipeline Execution Time} & 438 & \textbf{408} \\
    \bottomrule
\end{tabular*}
\end{table}

Mức cải thiện chủ yếu đến từ stage \textbf{train models}, nơi các mô hình \textbf{brf} và \textbf{xgb} được huấn luyện song song thay vì tuần tự. Tổng thời gian của stage này giảm từ 101 giây xuống còn 86 giây trong cấu hình song song. Cần lưu ý rằng trong thực nghiệm này, thời gian thực thi của từng tác vụ riêng lẻ (như train brf, train xgb, security check) có sự biến động nhẹ giữa hai lần chạy do điều kiện hạ tầng, nhưng cấu trúc song song vẫn giúp tối ưu tổng thời gian của cả cụm tác vụ. Các bước như preprocess data và compare models duy trì sự ổn định về thời gian thực thi giữa hai cấu hình.

Overhead time trong thực nghiệm được hiểu là phần thời gian không trực tiếp thuộc về các tác vụ xử lý chính của pipeline, bao gồm chi phí điều phối workflow (lập lịch DAG, đồng bộ phụ thuộc giữa các stage), tạo/khởi chạy pod và container, tải image, thiết lập môi trường chạy và các thao tác I/O trung gian. Trong cấu hình song song, nhờ việc tối ưu hóa luồng công việc, overhead time đã giảm từ 57 giây xuống còn 35 giây.

\paragraph{b. Đánh giá thời gian thực thi tái huấn luyện mô hình.}

Kết quả tương tự được quan sát trong Bảng~\ref{tab:compare_retraining_pipeline}, khi tổng thời gian thực thi quy trình tái huấn luyện giảm từ 695 giây xuống còn 578 giây, tương ứng mức cải thiện \textbf{16.8\%}.

Ở giai đoạn \textbf{prepare data}, việc song song hóa các bước fetch production data và get base data giúp giảm thời gian từ 49 giây xuống chỉ còn 9 giây. Stage \textbf{train models} tiếp tục là thành phần đóng góp chính vào việc rút ngắn thời gian thực thi, với tổng thời gian giảm từ 165 giây xuống còn 90 giây khi hai mô hình được huấn luyện đồng thời. Các stage còn lại như merge data, security check, preprocess data và compare models không chịu ảnh hưởng của cấu hình thực thi song song nên gần như không thay đổi.

\begin{table}[!htbp]
\centering
\caption{So sánh thời gian thực thi tái huấn luyện mô hình}
\label{tab:compare_retraining_pipeline}
\renewcommand{\arraystretch}{0.9}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} lcc}
    \toprule
    \textbf{Stage} & \textbf{Sequential (s)} & \textbf{Parallel (s)} \\
    \midrule
    \textbf{prepare data} & 49 & \textbf{9} \\
    \hspace{3mm} fetch production data & 35 & 9 \\
    \hspace{3mm} get base data & 14 & 9 \\
    \addlinespace
    merge data & 86 & 62 \\
    security check & 145 & 131 \\
    preprocess data & 114 & 124 \\
    \addlinespace
    \textbf{train models} & 165 & \textbf{90} \\
    \hspace{3mm} train brf & 90 & 90 \\
    \hspace{3mm} train xgb & 75 & 73 \\
    \addlinespace
    compare models & 28 & 26 \\
    Overhead time & 80 & \textbf{54} \\
    \midrule
    \textbf{Pipeline Execution Time} & 667 & \textbf{496} \\
    \bottomrule
\end{tabular*}
\end{table}

\paragraph{c. Đánh giá mức sử dụng tài nguyên.}

Nhằm đánh giá tác động của cấu hình thực thi song song lên mức sử dụng tài nguyên hệ thống, nhóm sinh viên tiến hành thực nghiệm và so sánh kết quả tại stage \textbf{Train Models} của quy trình huấn luyện mô hình. Bảng~\ref{tab:resource_utilization} trình bày mức sử dụng tài nguyên trung bình và mức sử dụng tài nguyên cao nhất trong quá trình huấn luyện hai mô hình đối với hai cấu hình thực thi tuần tự và song song.

Cụm \ac{eks} có tổng capacity là 8 vCPUs và 32 GB RAM. Tuy nhiên, do một phần tài nguyên được hệ thống Kubernetes và các thành phần nền tảng (kubelet, system daemons, applications) dự trữ và chiếm dụng, lượng tài nguyên thực tế có thể cấp phát cho workload chỉ còn \textbf{7.79 vCPUs và 29 GB RAM}. Tương ứng, mỗi node trong cụm có khoảng \textbf{1.9475 vCPUs và 7.25 GB RAM khả dụng}. 

Các chỉ số sử dụng CPU và bộ nhớ trong thực nghiệm được đo dựa trên phần tài nguyên khả dụng này, phản ánh chính xác mức độ khai thác tài nguyên khả dụng trong quá trình thực thi pipeline.

\begin{table}[!htbp]
\centering
\caption{So sánh mức sử dụng tài nguyên tại stage Train Models của quy trình huấn luyện mô hình}
\label{tab:resource_utilization}
\renewcommand{\arraystretch}{0.9}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} lcc}
    \toprule
    \textbf{Metrics} & \textbf{Sequential} & \textbf{Parallel} \\
    \midrule
    Avg. CPU Utilization & 5.31\% & 6.23\% \\
    Peak CPU Utilization & 7.14\% & 12.46\% \\
    \addlinespace
    Avg. Mem Utilization & 7.70\% & 17.78\% \\
    Peak Mem Utilization & 12.07\% & 21.01\% \\
    \bottomrule
\end{tabular*}
\end{table}

Mức sử dụng tài nguyên được tính theo công thức \eqref{eq:resource_utilization}, kết quả cho thấy khi chuyển từ thực thi tuần tự sang thực thi song song, mức sử dụng tài nguyên tăng lên rõ rệt nhằm đánh đổi lấy tốc độ xử lý. Cụ thể, \textbf{Peak CPU Utilization} (mức tiêu thụ CPU cao nhất) tăng từ 7.14\% lên 12.46\%, trong khi \textbf{Peak Memory Utilization} (mức tiêu thụ bộ nhớ cao nhất) tăng từ 12.07\% lên 21.01\%. Bên cạnh đó, \textbf{Avg. Mem Utilization} (mức tiêu thụ bộ nhớ trung bình) cũng ghi nhận mức tăng đáng kể từ 7.70\% lên 17.78\%. Điều này cho thấy cơ chế song song hóa trong kiến trúc DAG đã tận dụng hiệu quả hơn tài nguyên khả dụng của cụm Kubernetes.

Mặc dù mức tiêu thụ CPU và bộ nhớ cao hơn, các giá trị này vẫn nằm trong giới hạn an toàn của tài nguyên, cho phép pipeline đạt được sự cải thiện rõ rệt về thời gian thực thi mà không gây quá tải hệ thống.